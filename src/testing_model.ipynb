{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willd\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from text_denoiser import TextDenoiser\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10053, 228])\n",
      "torch.Size([10053, 228])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "denoiser = TextDenoiser(embed_dim=228, dim_feedforward=1024)\n",
    "denoiser.load_state_dict(torch.load(\"../logs/2000_lines/models/saved_model.pt\", map_location=device))\n",
    "print(denoiser.decoder.weight.shape)\n",
    "print(denoiser.embedder.weight.shape)\n",
    "# denoiser.decoder.weight = nn.Parameter(denoiser.embedder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.])\n",
      "tensor([17, 29,  9,  0])\n",
      "tensor(29.)\n"
     ]
    }
   ],
   "source": [
    "n_T = 40\n",
    "data = torch.ones(32, 4, 228)\n",
    "factor = torch.linspace(0, n_T-1, n_T)\n",
    "ts = torch.randint(0, n_T, (data.shape[1],))\n",
    "print(factor)\n",
    "print(ts)\n",
    "\n",
    "data = data * factor[None, ts, None]\n",
    "print(data[:, 1, :].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6th', 'entitled', 'brownish', 'steer', 'enraged']\n",
      "torch.Size([5, 10053])\n",
      "tensor([3635, 3160, 6918, 9531, 5221])\n",
      "['6th', 'entitled', 'brownish', 'steer', 'enraged']\n",
      "[3635, 3160, 6918, 9531, 5221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\AppData\\Local\\Temp\\ipykernel_16576\\3810622881.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  new_indices = torch.argmax(F.softmax(decoded), dim=-1)\n"
     ]
    }
   ],
   "source": [
    "texts = denoiser.vocab.lookup_tokens(torch.randint(0, len(denoiser.vocab), (5,)).tolist())\n",
    "print(texts)\n",
    "indices = torch.LongTensor(denoiser.vocab(texts)).to(device)\n",
    "\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "print(decoded.shape)\n",
    "new_indices = torch.argmax(F.softmax(decoded), dim=-1)\n",
    "print(new_indices)\n",
    "print(denoiser.vocab.lookup_tokens(new_indices.tolist()))\n",
    "\n",
    "print(denoiser.vocab(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating that cross entropy is calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices shape: torch.Size([128, 64])\n",
      "decoded shape: torch.Size([128, 64, 10053])\n",
      "tensor(0.0003, grad_fn=<NllLoss2DBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_len = 128\n",
    "indices = torch.randint(0, len(denoiser.vocab), (seq_len, batch_size))\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "# decoded = torch.randn(seq_len, batch_size, len(denoiser.vocab))\n",
    "print(\"indices shape:\", indices.shape)\n",
    "print(\"decoded shape:\", decoded.shape)\n",
    "\n",
    "# Calculate cross entropy loss\n",
    "# print(decoded.permute(0, 2, 1).shape)\n",
    "loss = F.cross_entropy(decoded.permute(1, 2, 0), indices.T)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "y = F.log_softmax(decoded, dim=-1).permute(0, 2, 1)\n",
    "reconstruction_loss = F.cross_entropy(y, indices)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of in in of of of of in of but in of in in of of of of in the in in of of to of of in the of in of in in of of of in of and the in in in in of of to in in of in of in of in of the in of in in in of the in of in in in in in in of of in of in in of in of of in of in in in in of of of in in in in in in in of in of in in in in in in in in in in in in of @-@ of in in of in of in of in in in of']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser.sample(device, 1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser.eval()\n",
    "seq_len = 16\n",
    "n = 1\n",
    "intermediates = []\n",
    "with torch.no_grad():\n",
    "    x = torch.randn((seq_len, n, denoiser.embed_dim), device=device)\n",
    "    for t in range(denoiser.n_T, 0, -1):\n",
    "        x = denoiser.sample_step(x, t)\n",
    "        if t % 100 == 0 or t == 1:\n",
    "            intermediates.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0495], grad_fn=<SumBackward1>)\n",
      "tensor([0.2288], grad_fn=<SumBackward1>)\n",
      "tensor([0.4992], grad_fn=<SumBackward1>)\n",
      "tensor([0.7436], grad_fn=<SumBackward1>)\n",
      "tensor([0.9075], grad_fn=<SumBackward1>)\n",
      "tensor([0.9684], grad_fn=<SumBackward1>)\n",
      "tensor([0.9856], grad_fn=<SumBackward1>)\n",
      "tensor([0.9943], grad_fn=<SumBackward1>)\n",
      "tensor([0.9978], grad_fn=<SumBackward1>)\n",
      "tensor([0.9994], grad_fn=<SumBackward1>)\n",
      "tensor([0.9999], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(intermediates, dim=0)\n",
    "stacked.shape\n",
    "arbitrary_word_emb = denoiser.embedder(torch.LongTensor(denoiser.vocab([\"of\"])).to(device))\n",
    "\n",
    "for x_i in stacked:\n",
    "    # print(x_i.shape)\n",
    "    print(F.cosine_similarity(x_i[0], arbitrary_word_emb, dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be to . by that = as that with that is were were as is that\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be as real and itself were over that this and team to this around was before\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "see as 80 up = from arms name god be but <unk> more are team not\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "uses to @ from , an in the a became which <unk> they consists , october\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of their this in including in in of as in of in and in as\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of on been in . in in of act in of in in in and\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in s in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_select = 0\n",
    "for x_i in stacked:\n",
    "    probs = F.softmax(denoiser.decoder(x_i), dim=-1)\n",
    "    print(probs.shape)\n",
    "    indices = indices = torch.multinomial(probs[:, batch_select], 1)[:, 0]\n",
    "    print(indices.shape)\n",
    "    # indices = denoiser.emb_to_indices(x_i)[:, batch_select]\n",
    "    tokens = denoiser.vocab.lookup_tokens(indices.tolist())\n",
    "    print(\" \".join(tokens))\n",
    "    probs[Dennis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0077], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"in\", \"of\", \"the\", \",\", \"mario\", \"peach\"]\n",
    "indices = torch.LongTensor(denoiser.vocab(words)).to(device)\n",
    "embeds = denoiser.embedder(indices)\n",
    "F.cosine_similarity(embeds[None, words.index(\"mario\")], embeds[None, words.index(\"peach\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.0457, grad_fn=<NormBackward1>)\n",
      "27.712812921102035\n",
      "[101, 7592, 1045, 1005, 1049, 1996, 2047, 2332, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS] hello i ' m the new king [SEP]\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup bert pipeline\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs[0]\n",
    "\n",
    "\n",
    "# text = \"shovel bucket\"\n",
    "# tokens = tokenizer.tokenize(text)\n",
    "# tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# token_ids = torch.LongTensor(token_ids).unsqueeze(0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(token_ids)\n",
    "#     last_hidden_states = outputs[0]\n",
    "\n",
    "# print(last_hidden_states[0, 1, 0:3])\n",
    "\n",
    "emb1 = get_embedding(\"\", model, tokenizer)\n",
    "emb2 = get_embedding(\"bathroom\", model, tokenizer)\n",
    "\n",
    "print(emb1[0, 1].norm())\n",
    "print(emb1.shape[-1] ** 0.5)\n",
    "\n",
    "# Cosine similarity between \"shovel\" and \"bucket\" embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(last_hidden_states[0, 1:2], last_hidden_states[0, 2:3]))\n",
    "# print(model.get_output_embeddings())\n",
    "\n",
    "# Cosine similarity between embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(emb1[0, 0:1], emb2[0, 0]))\n",
    "\n",
    "# inverse process: get text from embedding\n",
    "tokens = tokenizer(\"Hello I'm the new king\")[\"input_ids\"]\n",
    "print(tokens)\n",
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58b3ebf8dec169d8aec70c36b552225c97668c5e5a4c1d2a670fb746efb28189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
