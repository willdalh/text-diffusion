{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_denoiser import TextDenoiser\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "if os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"..\")\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from get_dataset_and_vocab import get_dataset_and_vocab\n",
    "from utils import text_collate_fn, read_glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([574, 100])\n",
      "torch.Size([574, 100])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\willd\\OneDrive - NTNU\\Documents\\Skole\\U9\\Advanced Text Analytics and Language Understanding\\text-diffusion\\src\\testing_model.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willd/OneDrive%20-%20NTNU/Documents/Skole/U9/Advanced%20Text%20Analytics%20and%20Language%20Understanding/text-diffusion/src/testing_model.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(denoiser\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/willd/OneDrive%20-%20NTNU/Documents/Skole/U9/Advanced%20Text%20Analytics%20and%20Language%20Understanding/text-diffusion/src/testing_model.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(denoiser\u001b[39m.\u001b[39membedder\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/willd/OneDrive%20-%20NTNU/Documents/Skole/U9/Advanced%20Text%20Analytics%20and%20Language%20Understanding/text-diffusion/src/testing_model.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(denoiser\u001b[39m.\u001b[39membedder(torch\u001b[39m.\u001b[39mLongTensor([vocab[\u001b[39m\"\u001b[39m\u001b[39mthe\u001b[39m\u001b[39m\"\u001b[39m]])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "denoiser = TextDenoiser.load_from_training_log(\"logs/train_test\", \"saved_model.pt\", device)\n",
    "denoiser.eval()\n",
    "print(denoiser.decoder.weight.shape)\n",
    "print(denoiser.embedder.weight.shape)\n",
    "# denoiser.decoder.weight = nn.Parameter(denoiser.embedder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikitext2\n"
     ]
    }
   ],
   "source": [
    "dataset, vocab = get_dataset_and_vocab(\"wikitext2\", seq_len=32, line_slice=20)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=1, collate_fn=text_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n",
      "lose face in the war . while at times this works to their advantage , such as a successful incursion into imperial territory , other orders cause certain members of the 422nd\n",
      "tensor([0.3589, 0.3586, 0.7197], grad_fn=<SliceBackward0>)\n",
      "tensor([0.3649, 0.3552, 0.5994])\n",
      "tensor([0.3281, 0.3493, 0.5572])\n",
      "lose face in the war . while at times this works to their advantage , such as a successful incursion into imperial territory , other orders cause certain members of the 422nd\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_emb = denoiser.embedder(x)\n",
    "print(denoiser.emb_to_str(x_emb)[0])\n",
    "t_noised = 10\n",
    "ts = torch.LongTensor([t_noised]*x.shape[1]).to(device)\n",
    "stored = []\n",
    "print(x_emb[0, 0, 0:3])\n",
    "with torch.no_grad():\n",
    "    x_emb_noised, eps = denoiser.noise(x_emb, ts)\n",
    "    print(x_emb_noised[0, 0, 0:3])\n",
    "    x_t = x_emb_noised.clone()\n",
    "    for t in range(t_noised, 0, -1):\n",
    "        x_t = denoiser.sample_step(x_t, t)\n",
    "        stored.append(x_t[0, 0, 0].item())\n",
    "\n",
    "    # print(denoiser.emb_to_tokens(x_emb)[3])\n",
    "print(x_t[0, 0, 0:3])\n",
    "print(denoiser.emb_to_str(x_t)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "         -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "          0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "          0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "          0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "         -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "         -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "          0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "          1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "         -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "          0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "          0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "         -0.5203, -0.1459,  0.8278,  0.2706]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x229dac22c20>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_emb = denoiser.embedder(torch.LongTensor([denoiser.vocab[\"the\"]]))\n",
    "print(test_emb)\n",
    "\n",
    "# denoiser.vocab[\".\"]\n",
    "plt.plot(stored)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitlake\n",
      "<unk>\n",
      "@-@\n",
      "nṯr\n",
      "leadeth\n",
      "biotrophic\n",
      "grivičić\n",
      "sulfoxonium\n",
      "atenism\n",
      "bhringi\n",
      "amadito\n",
      "geopyxis\n",
      "praška\n",
      "trinsey\n",
      "maskrays\n",
      "æsthetic\n",
      "fruitbodies\n",
      "iconographies\n",
      "neotrygon\n",
      "fitwatch\n",
      "żeleński\n",
      "maskray\n",
      "chaykovsky\n",
      "noisescapes\n",
      "carbenoid\n",
      "annotata\n",
      "ziltoid\n",
      "44b\n",
      "methanide\n",
      "sulfonium\n",
      "biomech\n",
      "gharapuri\n",
      "aziridines\n",
      "estañol\n",
      "gasar\n",
      "dahau\n",
      "rushie\n",
      "senjō\n",
      "₹\n",
      "²\n",
      "andhaka\n",
      "darcsen\n",
      "ir8\n",
      "m1822\n",
      "waldrons\n",
      "yogishvara\n",
      "µm\n",
      "crimint\n",
      "°\n",
      "epicloud\n",
      "gilii\n",
      "ginczanka\n",
      "honjou\n",
      "khenty\n",
      "riela\n",
      "synchestra\n",
      "terria\n",
      "戦場のヴァルキュリア3\n",
      "000th\n",
      "casemated\n",
      "ectomycorrhizae\n",
      "impétueux\n",
      "kalyanasundara\n",
      "†\n"
     ]
    }
   ],
   "source": [
    "embeddings = read_glove_vectors(\"resources/glove.6B.100d.txt\", vocab, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10053, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.])\n",
      "tensor([ 1, 11])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "n_T = 40\n",
    "data = torch.ones(4, 2, 3)\n",
    "factor = torch.linspace(0, n_T-1, n_T)\n",
    "ts = torch.randint(0, n_T, (data.shape[1],))\n",
    "print(factor)\n",
    "print(ts)\n",
    "print(data)\n",
    "data = data * factor[None, ts, None]\n",
    "# print(data[:, 1, :].mean())\n",
    "# print(data[:, 1,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impressed', 'running', 'presents', 'collection', 'refugees']\n",
      "torch.Size([5, 10053])\n",
      "tensor([4117, 2812, 8980, 3814, 9150])\n",
      "['impressed', 'running', 'presents', 'collection', 'refugees']\n",
      "[4117, 2812, 8980, 3814, 9150]\n"
     ]
    }
   ],
   "source": [
    "texts = denoiser.vocab.lookup_tokens(torch.randint(0, len(denoiser.vocab), (5,)).tolist())\n",
    "print(texts)\n",
    "indices = torch.LongTensor(denoiser.vocab(texts)).to(device)\n",
    "\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "print(decoded.shape)\n",
    "new_indices = torch.argmax(F.softmax(decoded, dim=-1), dim=-1)\n",
    "print(new_indices)\n",
    "print(denoiser.vocab.lookup_tokens(new_indices.tolist()))\n",
    "\n",
    "print(denoiser.vocab(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating that cross entropy is calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices shape: torch.Size([128, 64])\n",
      "decoded shape: torch.Size([128, 64, 10053])\n",
      "tensor(0.0004, grad_fn=<NllLoss2DBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_len = 128\n",
    "indices = torch.randint(0, len(denoiser.vocab), (seq_len, batch_size))\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "# decoded = torch.randn(seq_len, batch_size, len(denoiser.vocab))\n",
    "print(\"indices shape:\", indices.shape)\n",
    "print(\"decoded shape:\", decoded.shape)\n",
    "\n",
    "# Calculate cross entropy loss\n",
    "# print(decoded.permute(0, 2, 1).shape)\n",
    "loss = F.cross_entropy(decoded.permute(1, 2, 0), indices.T)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "y = F.log_softmax(decoded, dim=-1).permute(0, 2, 1)\n",
    "reconstruction_loss = F.cross_entropy(y, indices)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of the the the the the community the a of of the the of of the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser.sample(device, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser.eval()\n",
    "seq_len = 16\n",
    "n = 1\n",
    "intermediates = []\n",
    "with torch.no_grad():\n",
    "    x = torch.randn((seq_len, n, denoiser.embed_dim), device=device)\n",
    "    for t in range(denoiser.n_T, 0, -1):\n",
    "        x = denoiser.sample_step(x, t)\n",
    "        if t % 100 == 0 or t == 1:\n",
    "            intermediates.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0495], grad_fn=<SumBackward1>)\n",
      "tensor([0.2288], grad_fn=<SumBackward1>)\n",
      "tensor([0.4992], grad_fn=<SumBackward1>)\n",
      "tensor([0.7436], grad_fn=<SumBackward1>)\n",
      "tensor([0.9075], grad_fn=<SumBackward1>)\n",
      "tensor([0.9684], grad_fn=<SumBackward1>)\n",
      "tensor([0.9856], grad_fn=<SumBackward1>)\n",
      "tensor([0.9943], grad_fn=<SumBackward1>)\n",
      "tensor([0.9978], grad_fn=<SumBackward1>)\n",
      "tensor([0.9994], grad_fn=<SumBackward1>)\n",
      "tensor([0.9999], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(intermediates, dim=0)\n",
    "stacked.shape\n",
    "arbitrary_word_emb = denoiser.embedder(torch.LongTensor(denoiser.vocab([\"of\"])).to(device))\n",
    "\n",
    "for x_i in stacked:\n",
    "    # print(x_i.shape)\n",
    "    print(F.cosine_similarity(x_i[0], arbitrary_word_emb, dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be to . by that = as that with that is were were as is that\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be as real and itself were over that this and team to this around was before\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "see as 80 up = from arms name god be but <unk> more are team not\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "uses to @ from , an in the a became which <unk> they consists , october\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of their this in including in in of as in of in and in as\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of on been in . in in of act in of in in in and\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in s in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_select = 0\n",
    "for x_i in stacked:\n",
    "    probs = F.softmax(denoiser.decoder(x_i), dim=-1)\n",
    "    print(probs.shape)\n",
    "    indices = indices = torch.multinomial(probs[:, batch_select], 1)[:, 0]\n",
    "    print(indices.shape)\n",
    "    # indices = denoiser.emb_to_indices(x_i)[:, batch_select]\n",
    "    tokens = denoiser.vocab.lookup_tokens(indices.tolist())\n",
    "    print(\" \".join(tokens))\n",
    "    # probs[Dennis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0077], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"in\", \"of\", \"the\", \",\", \"mario\", \"peach\"]\n",
    "indices = torch.LongTensor(denoiser.vocab(words)).to(device)\n",
    "embeds = denoiser.embedder(indices)\n",
    "F.cosine_similarity(embeds[None, words.index(\"mario\")], embeds[None, words.index(\"peach\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.0457, grad_fn=<NormBackward1>)\n",
      "27.712812921102035\n",
      "[101, 7592, 1045, 1005, 1049, 1996, 2047, 2332, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS] hello i ' m the new king [SEP]\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup bert pipeline\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs[0]\n",
    "\n",
    "\n",
    "# text = \"shovel bucket\"\n",
    "# tokens = tokenizer.tokenize(text)\n",
    "# tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# token_ids = torch.LongTensor(token_ids).unsqueeze(0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(token_ids)\n",
    "#     last_hidden_states = outputs[0]\n",
    "\n",
    "# print(last_hidden_states[0, 1, 0:3])\n",
    "\n",
    "emb1 = get_embedding(\"\", model, tokenizer)\n",
    "emb2 = get_embedding(\"bathroom\", model, tokenizer)\n",
    "\n",
    "print(emb1[0, 1].norm())\n",
    "print(emb1.shape[-1] ** 0.5)\n",
    "\n",
    "# Cosine similarity between \"shovel\" and \"bucket\" embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(last_hidden_states[0, 1:2], last_hidden_states[0, 2:3]))\n",
    "# print(model.get_output_embeddings())\n",
    "\n",
    "# Cosine similarity between embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(emb1[0, 0:1], emb2[0, 0]))\n",
    "\n",
    "# inverse process: get text from embedding\n",
    "tokens = tokenizer(\"Hello I'm the new king\")[\"input_ids\"]\n",
    "print(tokens)\n",
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58b3ebf8dec169d8aec70c36b552225c97668c5e5a4c1d2a670fb746efb28189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
