{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_denoiser import TextDenoiser\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "if os.getcwd().endswith(\"src\"):\n",
    "    os.chdir(\"..\")\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from get_dataset_and_vocab import get_dataset_and_vocab\n",
    "from utils import text_collate_fn, read_glove_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8])\n",
      "torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "denoiser = TextDenoiser.load_from_training_log(\"logs/train_test\", \"saved_model.pt\", device)\n",
    "denoiser.eval()\n",
    "print(denoiser.decoder.weight.shape)\n",
    "print(denoiser.embedder.weight.shape)\n",
    "# denoiser.decoder.weight = nn.Parameter(denoiser.embedder.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimal\n"
     ]
    }
   ],
   "source": [
    "dataset, vocab = get_dataset_and_vocab(\"minimal\", seq_len=4, line_slice=2000)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=1, collate_fn=text_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "am sentient and am\n",
      "tensor([-0.5493,  1.3723, -0.0172], grad_fn=<SliceBackward0>)\n",
      "tensor([-0.5005,  1.7477,  0.4934])\n",
      "tensor([-0.3938,  0.7169,  0.8616])\n",
      "am the live you\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_emb = denoiser.embedder(x)\n",
    "print(denoiser.emb_to_str(x_emb)[0])\n",
    "t_noised = 100\n",
    "ts = torch.LongTensor([t_noised]*x.shape[1]).to(device)\n",
    "stored = []\n",
    "print(x_emb[0, 0, 0:3])\n",
    "with torch.no_grad():\n",
    "    x_emb_noised, eps = denoiser.noise(x_emb, ts)\n",
    "    print(x_emb_noised[0, 0, 0:3])\n",
    "    x_t = x_emb_noised.clone()\n",
    "    for t in range(t_noised, 0, -1):\n",
    "        x_t = denoiser.sample_step(x_t, t)\n",
    "        stored.append(x_t[0, 0, 0].item())\n",
    "\n",
    "    # print(denoiser.emb_to_tokens(x_emb)[3])\n",
    "print(x_t[0, 0, 0:3])\n",
    "print(denoiser.emb_to_str(x_t)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0811, grad_fn=<NormBackward1>)\n",
      "tensor(3.3641, grad_fn=<NormBackward1>)\n",
      "tensor([[-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "         -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "          0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "          0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "          0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "         -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "         -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "          0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "          1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "         -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "          0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "          0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "         -0.5203, -0.1459,  0.8278,  0.2706]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2e0b7974f10>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_emb = denoiser.embedder(torch.LongTensor([denoiser.vocab[\"the\"]]))\n",
    "print(test_emb)\n",
    "\n",
    "# denoiser.vocab[\".\"]\n",
    "plt.plot(stored)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9989 out of 10053 words in GloVe\n"
     ]
    }
   ],
   "source": [
    "embeddings = read_glove_vectors(\"resources/glove.6B.100d.txt\", vocab, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.])\n",
      "tensor([ 1, 11])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "n_T = 40\n",
    "data = torch.ones(4, 2, 3)\n",
    "factor = torch.linspace(0, n_T-1, n_T)\n",
    "ts = torch.randint(0, n_T, (data.shape[1],))\n",
    "print(factor)\n",
    "print(ts)\n",
    "print(data)\n",
    "data = data * factor[None, ts, None]\n",
    "# print(data[:, 1, :].mean())\n",
    "# print(data[:, 1,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'not', '<unk>', 'sentient', 'world']\n",
      "torch.Size([5, 16])\n",
      "tensor([ 6,  9,  3, 15,  9])\n",
      "['in', 'not', 'and', 'you', 'not']\n",
      "[15, 9, 0, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "texts = denoiser.vocab.lookup_tokens(torch.randint(0, len(denoiser.vocab), (5,)).tolist())\n",
    "print(texts)\n",
    "indices = torch.LongTensor(denoiser.vocab(texts)).to(device)\n",
    "\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "print(decoded.shape)\n",
    "new_indices = torch.argmax(F.softmax(decoded, dim=-1), dim=-1)\n",
    "print(new_indices)\n",
    "print(denoiser.vocab.lookup_tokens(new_indices.tolist()))\n",
    "\n",
    "print(denoiser.vocab(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating that cross entropy is calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices shape: torch.Size([128, 64])\n",
      "decoded shape: torch.Size([128, 64, 10053])\n",
      "tensor(0.0004, grad_fn=<NllLoss2DBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_len = 128\n",
    "indices = torch.randint(0, len(denoiser.vocab), (seq_len, batch_size))\n",
    "embeds = denoiser.embedder(indices)\n",
    "embeds.shape\n",
    "\n",
    "decoded = denoiser.decoder(embeds)\n",
    "# decoded = torch.randn(seq_len, batch_size, len(denoiser.vocab))\n",
    "print(\"indices shape:\", indices.shape)\n",
    "print(\"decoded shape:\", decoded.shape)\n",
    "\n",
    "# Calculate cross entropy loss\n",
    "# print(decoded.permute(0, 2, 1).shape)\n",
    "loss = F.cross_entropy(decoded.permute(1, 2, 0), indices.T)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "y = F.log_softmax(decoded, dim=-1).permute(0, 2, 1)\n",
    "reconstruction_loss = F.cross_entropy(y, indices)\n",
    "print(reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of the the the the the community the a of of the the of of the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser.sample(device, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser.eval()\n",
    "seq_len = 16\n",
    "n = 1\n",
    "intermediates = []\n",
    "with torch.no_grad():\n",
    "    x = torch.randn((seq_len, n, denoiser.embed_dim), device=device)\n",
    "    for t in range(denoiser.n_T, 0, -1):\n",
    "        x = denoiser.sample_step(x, t)\n",
    "        if t % 100 == 0 or t == 1:\n",
    "            intermediates.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0495], grad_fn=<SumBackward1>)\n",
      "tensor([0.2288], grad_fn=<SumBackward1>)\n",
      "tensor([0.4992], grad_fn=<SumBackward1>)\n",
      "tensor([0.7436], grad_fn=<SumBackward1>)\n",
      "tensor([0.9075], grad_fn=<SumBackward1>)\n",
      "tensor([0.9684], grad_fn=<SumBackward1>)\n",
      "tensor([0.9856], grad_fn=<SumBackward1>)\n",
      "tensor([0.9943], grad_fn=<SumBackward1>)\n",
      "tensor([0.9978], grad_fn=<SumBackward1>)\n",
      "tensor([0.9994], grad_fn=<SumBackward1>)\n",
      "tensor([0.9999], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(intermediates, dim=0)\n",
    "stacked.shape\n",
    "arbitrary_word_emb = denoiser.embedder(torch.LongTensor(denoiser.vocab([\"of\"])).to(device))\n",
    "\n",
    "for x_i in stacked:\n",
    "    # print(x_i.shape)\n",
    "    print(F.cosine_similarity(x_i[0], arbitrary_word_emb, dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be to . by that = as that with that is were were as is that\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "be as real and itself were over that this and team to this around was before\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "see as 80 up = from arms name god be but <unk> more are team not\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "uses to @ from , an in the a became which <unk> they consists , october\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of their this in including in in of as in of in and in as\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of on been in . in in of act in of in in in and\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in s in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of jordan of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n",
      "torch.Size([16, 1, 10053])\n",
      "torch.Size([16])\n",
      "of of in of in of in in of of in of in in in of\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_select = 0\n",
    "for x_i in stacked:\n",
    "    probs = F.softmax(denoiser.decoder(x_i), dim=-1)\n",
    "    print(probs.shape)\n",
    "    indices = indices = torch.multinomial(probs[:, batch_select], 1)[:, 0]\n",
    "    print(indices.shape)\n",
    "    # indices = denoiser.emb_to_indices(x_i)[:, batch_select]\n",
    "    tokens = denoiser.vocab.lookup_tokens(indices.tolist())\n",
    "    print(\" \".join(tokens))\n",
    "    # probs[Dennis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0077], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"in\", \"of\", \"the\", \",\", \"mario\", \"peach\"]\n",
    "indices = torch.LongTensor(denoiser.vocab(words)).to(device)\n",
    "embeds = denoiser.embedder(indices)\n",
    "F.cosine_similarity(embeds[None, words.index(\"mario\")], embeds[None, words.index(\"peach\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.0457, grad_fn=<NormBackward1>)\n",
      "27.712812921102035\n",
      "[101, 7592, 1045, 1005, 1049, 1996, 2047, 2332, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[CLS] hello i ' m the new king [SEP]\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup bert pipeline\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs[0]\n",
    "\n",
    "\n",
    "# text = \"shovel bucket\"\n",
    "# tokens = tokenizer.tokenize(text)\n",
    "# tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# token_ids = torch.LongTensor(token_ids).unsqueeze(0)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(token_ids)\n",
    "#     last_hidden_states = outputs[0]\n",
    "\n",
    "# print(last_hidden_states[0, 1, 0:3])\n",
    "\n",
    "emb1 = get_embedding(\"\", model, tokenizer)\n",
    "emb2 = get_embedding(\"bathroom\", model, tokenizer)\n",
    "\n",
    "print(emb1[0, 1].norm())\n",
    "print(emb1.shape[-1] ** 0.5)\n",
    "\n",
    "# Cosine similarity between \"shovel\" and \"bucket\" embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(last_hidden_states[0, 1:2], last_hidden_states[0, 2:3]))\n",
    "# print(model.get_output_embeddings())\n",
    "\n",
    "# Cosine similarity between embeddings\n",
    "# print(torch.nn.functional.cosine_similarity(emb1[0, 0:1], emb2[0, 0]))\n",
    "\n",
    "# inverse process: get text from embedding\n",
    "tokens = tokenizer(\"Hello I'm the new king\")[\"input_ids\"]\n",
    "print(tokens)\n",
    "tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58b3ebf8dec169d8aec70c36b552225c97668c5e5a4c1d2a670fb746efb28189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
